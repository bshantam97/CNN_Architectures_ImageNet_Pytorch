{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "# Ignore Harmless Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, in_channels = 3, num_classes = 2):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.conv1 = conv_block(in_channels = in_channels, out_channels = 64, kernel_size = (7,7),\n",
    "                               stride = (2,2), padding = (3,3))\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.conv2 = conv_block(64, 192,kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.inception3a = Inception_block(192,64,96,128,16,32,32)\n",
    "        self.inception3b = Inception_block(256,128,128,192,32,96,64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.inception4a = Inception_block(480,192,96,208,16,48,64)\n",
    "        self.inception4b = Inception_block(512,160,112,224,24,64,64)\n",
    "        self.inception4c = Inception_block(512,128,128,256,24,64,64)\n",
    "        self.inception4d = Inception_block(512,112,144,288,32,64,64)\n",
    "        self.inception4e = Inception_block(528,256,160,320,32,128,128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.inception5a = Inception_block(832, 256,160,320,32,128,128)\n",
    "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size = 7, stride = 1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(1024,num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "class Inception_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
    "        \n",
    "        super(Inception_block, self).__init__()\n",
    "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size = 1)\n",
    "        self.branch2 = nn.Sequential(conv_block(in_channels, red_3x3, kernel_size = 1),\n",
    "                                    conv_block(red_3x3, out_3x3,kernel_size = 3, padding = 1))\n",
    "        self.branch3 = nn.Sequential(conv_block(in_channels, red_5x5, kernel_size = 1),\n",
    "                                    conv_block(red_5x5, out_5x5, kernel_size = 5, padding = 2))\n",
    "        self.branch4 = nn.Sequential(nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
    "                                    conv_block(in_channels, out_1x1pool, kernel_size = 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Nx filtersx 28 x 28\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs) # kernel_size = (1,1), (2,2), (3,3)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation for the training dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(), # Default probability of 0.5\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], # Mean and standard deviation for each colour channel\n",
    "                        [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Data Augmentation for the testing dataset\n",
    "# We dont need to perform random flips or rotations in the dataset\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                        [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "root = 'C:\\\\Users\\\\shant\\\\CNN_Architectures_ImageNet_Pytorch\\\\Dataset\\\\CATS_DOGS\\\\'\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(root, 'train'), transform = train_transform)\n",
    "\n",
    "test_data = datasets.ImageFolder(os.path.join(root, 'test'), transform = test_transform)\n",
    "\n",
    "# Set the manual seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = 10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 LOSS 0.7474378347396851\n"
     ]
    }
   ],
   "source": [
    "device  = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Object for the GoogleNet class\n",
    "Googlenet = GoogleNet(in_channels = 3, num_classes = 2)\n",
    "Googlenet.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(Googlenet.parameters(), lr = 0.001)\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "max_train_batch = 800 # Batch of 10 images --> 8000 Images\n",
    "max_test_batch = 300 # Batch of 10 images --> 300 Images\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  trn_corr = 0\n",
    "  tst_corr = 0\n",
    "\n",
    "  for b, (x_train, y_train) in enumerate(train_loader):\n",
    "\n",
    "    x_train = x_train.cuda()\n",
    "    y_train = y_train.cuda()\n",
    "\n",
    "    # Limit the number of batches\n",
    "    if b == max_train_batch:\n",
    "      break\n",
    "    b += 1\n",
    "        \n",
    "    y_pred = Googlenet(x_train)\n",
    "    loss = criterion(y_pred,y_train)\n",
    "        \n",
    "    # Tally number of correct predictions\n",
    "    #predicted = torch.max(y_pred.data,1)[1]\n",
    "    #batch_corr = (predicted == y_train).sum()\n",
    "    #trn_corr += batch_corr\n",
    "        \n",
    "    # Update the Parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if b%200 == 0:\n",
    "\n",
    "      print(f'Epoch {i} LOSS {loss.item()}')\n",
    "    \n",
    "    #train_losses.append(loss)\n",
    "    #train_correct.append(trn_corr)\n",
    "    \n",
    "    #TEST SET  \n",
    "total_time = time.time() - start_time\n",
    "print(f'Total Time: {total_time/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
